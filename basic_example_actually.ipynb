{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Example for Section 4 Bounds\n",
    "\n",
    "This is a simple example of computing the bounds in section 4 (theorems 4.8 and 4.9) with $\\dim(\\mathcal{O}) = 2$ with features [\"pill taken?\", \"headache relief?\"] and three selected possible causes: [\"aspirin\",\"caffeine\", \"placebo\"]. We derive bounds for all three possible causes.\n",
    "\n",
    "To help with intuition, this example uses normalized posterior probabilities (i.e., $\\Pr(\\mathbf{x})$ in the denominator), but produces the same results as the ranking is the same.\n",
    "\n",
    "### Define Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Posterior:\n",
    "    def __init__(self,lower:float, upper:float, color:str, name:str, distribution_type=\"uniform\") -> None:\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.color = color\n",
    "        self.name = name\n",
    "        self.distribution_type = distribution_type\n",
    "        return\n",
    "    def get_bounds(self):\n",
    "        return [self.lower, self.upper]\n",
    "    \n",
    "    def get_pdf(self,x): \n",
    "        if self.distribution_type == \"uniform\":\n",
    "            return 1/(self.upper - self.lower)\n",
    "        else:\n",
    "            return ValueError(\"No other methods supported\")\n",
    "        \n",
    "class Cause:\n",
    "    def __init__(self, name:str, likelihood_dist_l:List[List[float]], likelihood_dist_u:List[List[float]], \n",
    "                 prior_l:float, prior_u:float, evidence_dist:List[List[float]]) -> None:\n",
    "        self.name = name\n",
    "        self.likelihood_dist_l = likelihood_dist_l\n",
    "        self.likelihood_dist_u = likelihood_dist_u\n",
    "        self.prior_l = prior_l\n",
    "        self.prior_u = prior_u\n",
    "        self.evidence_dist = evidence_dist\n",
    "        self.posteriors = self.populate_posteriors() # array of posterior objects for every observation vect\n",
    "        \n",
    "        return \n",
    "    def populate_posteriors(self):\n",
    "        posteriors = [[None,None],[None,None]]\n",
    "        for i in [0,1]:\n",
    "            for j in [0,1]:\n",
    "                lower_posterior = self.likelihood_dist_l[i][j]*self.prior_l/self.evidence_dist[i][j]\n",
    "                upper_posterior = self.likelihood_dist_u[i][j]*self.prior_u/self.evidence_dist[i][j]\n",
    "                posteriors[i][j] = Posterior(lower=lower_posterior,\n",
    "                                                  upper=upper_posterior,\n",
    "                                                  color=\"blue\",\n",
    "                                                  name=f\"Posterior of {self.name} for observation {[i,j]}\")\n",
    "        return  posteriors\n",
    "    def display_posteriors(self):\n",
    "        print(f\"Lower posteriors of cause {self.name}:\")\n",
    "        print(self.posteriors[0][0].lower, self.posteriors[0][1].lower)\n",
    "        print(self.posteriors[1][0].lower, self.posteriors[1][1].lower)\n",
    "        print(f\"\\nUpper posteriors of cause {self.name}:\")\n",
    "        print(self.posteriors[0][0].upper, self.posteriors[0][1].upper)\n",
    "        print(self.posteriors[1][0].upper, self.posteriors[1][1].upper)\n",
    "        return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create evidence distribution. Indices of the evidence distribution are as follows\n",
    "\n",
    "- (0,0)=(no pill taken, no headache relieved)\n",
    "- (0,1)=(no pill taken, headache relieved)\n",
    "\n",
    "- (1,0)=(pill taken,  no headache relieved) \n",
    "- (1,1)=(pill taken, headache relieved)\n",
    "\n",
    "This is the only fixed probability assumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVIDENCE_DIST = [[0.3, 0.05],\n",
    "                 [0.15, 0.5]]\n",
    "Q_CONFIDENCE = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare likelihood and prior ranges for each each cause: Aspirin, Placebo Pill, Caffeine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower posteriors of cause aspirin:\n",
      "0.016666666666666666 0.0\n",
      "0.16666666666666669 0.2\n",
      "\n",
      "Upper posteriors of cause aspirin:\n",
      "0.1 0.13999999999999999\n",
      "0.5333333333333333 0.8\n"
     ]
    }
   ],
   "source": [
    "# aspirin\n",
    "aspirin_likelihood_u = np.array([[0.03,0.007],\n",
    "                                  [0.08,0.4]])/0.517\n",
    "aspirin_likelihood_l = [[0.02,0],\n",
    "                        [0.10,0.4]]\n",
    "aspirin_prior_l = 0.25\n",
    "aspirin_prior_u = 0.517\n",
    "\n",
    "aspirin = Cause(name=\"aspirin\",\n",
    "                likelihood_dist_l=aspirin_likelihood_l, \n",
    "                likelihood_dist_u=aspirin_likelihood_u,\n",
    "                prior_l=aspirin_prior_l,\n",
    "                prior_u=aspirin_prior_u,\n",
    "                evidence_dist=EVIDENCE_DIST)\n",
    "\n",
    "\n",
    "aspirin.display_posteriors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower posteriors of cause placebo:\n",
      "0.006666666666666667 0.0\n",
      "0.33333333333333337 0.010000000000000002\n",
      "\n",
      "Upper posteriors of cause placebo:\n",
      "0.06666666666666667 0.06\n",
      "0.4 0.06\n"
     ]
    }
   ],
   "source": [
    "# placebo\n",
    "# (0,0)=(no pill taken, no headache relieved) | (0,1)=(no pill taken, headache relieved)\n",
    "# (1,0)=(pill taken,  no headache relieved)   | (1,1)=(pill taken, headache relieved)\n",
    "\n",
    "placebo_likelihood_u = np.array([[0.02,0.003],\n",
    "                        [0.06,0.03]])/0.113\n",
    "placebo_likelihood_l = [[0.02,0],\n",
    "                        [0.5,0.05]]\n",
    "placebo_prior_l = 0.1\n",
    "placebo_prior_u = 0.113\n",
    "\n",
    "placebo = Cause(name=\"placebo\",\n",
    "                likelihood_dist_l=placebo_likelihood_l, \n",
    "                likelihood_dist_u=placebo_likelihood_u,\n",
    "                prior_l=placebo_prior_l,\n",
    "                prior_u=placebo_prior_u,\n",
    "                evidence_dist=EVIDENCE_DIST)\n",
    "\n",
    "\n",
    "placebo.display_posteriors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower posteriors of cause caffeine:\n",
      "0.06666666666666668 0.10000000000000002\n",
      "0.0 0.010000000000000002\n",
      "\n",
      "Upper posteriors of cause caffeine:\n",
      "0.8333333333333334 0.7999999999999999\n",
      "0.06666666666666667 0.14\n"
     ]
    }
   ],
   "source": [
    "# caffeine\n",
    "# (0,0)=(no pill taken, no headache relieved) | (0,1)=(no pill taken, headache relieved)\n",
    "# (1,0)=(pill taken,  no headache relieved)   | (1,1)=(pill taken, headache relieved)\n",
    "\n",
    "caffeine_likelihood_u = np.array([[0.25,0.04],        # began with posteriors for toy example\n",
    "                                  [0.01,0.07]])/0.37\n",
    "\n",
    "caffeine_likelihood_l = [[0.2,0.05],\n",
    "                        [0.0,0.05]]\n",
    "caffeine_prior_l = 0.1\n",
    "caffeine_prior_u = 0.37\n",
    "\n",
    "caffeine = Cause(name=\"caffeine\",\n",
    "                likelihood_dist_l=caffeine_likelihood_l, \n",
    "                likelihood_dist_u=caffeine_likelihood_u,\n",
    "                prior_l=caffeine_prior_l,\n",
    "                prior_u=caffeine_prior_u,\n",
    "                evidence_dist=EVIDENCE_DIST)\n",
    "\n",
    "\n",
    "caffeine.display_posteriors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that sum of upper bounds of posteriors are less than or equal to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9999999999999999\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in [0,1]:\n",
    "    for j in [0,1]:\n",
    "        print(caffeine.posteriors[i][j].upper+placebo.posteriors[i][j].upper+aspirin.posteriors[i][j].upper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define example posteriors along with 95% confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define observation ector\n",
    "pill = 1 # pill is present\n",
    "relief = 0 # headache not relieved\n",
    "\n",
    "\n",
    "# OLD WAY\n",
    "# aspirin = Posterior(lower=0.23, upper=0.3, name=\"Aspirin\", color=\"blue\")\n",
    "# placebo = Posterior(lower=0.15, upper=0.25, name=\"Placebo\", color=\"red\")\n",
    "# caffeine = Posterior(lower=0.2, upper=0.4, name=\"Caffiene\", color=\"orange\")\n",
    "# cyanide = Posterior(lower=0, upper=0.002, name=\"Cyanide\", color=\"green\")\n",
    "\n",
    "aspirin_post = aspirin.posteriors[pill][relief]\n",
    "placebo_post = placebo.posteriors[pill][relief]\n",
    "caffeine_post = caffeine.posteriors[pill][relief]\n",
    "\n",
    "aspirin_post.color = \"red\"\n",
    "caffeine_post.color = \"orange\"\n",
    "\n",
    "posteriors = [aspirin_post,\n",
    "              placebo_post,\n",
    "              caffeine_post]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 95% confidence posterior ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Posterior Confidence Bounds')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAEWCAYAAACexWadAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAr80lEQVR4nO3debhcRYH+8e8rCZuENfkxoEAUQQYRI1xQFlmEQUCEiDBRGTWIMuyDiMg4iICMw+IgCO6ALCoiCBoBWWTREJYQloRFURSQTbgsAwES1vf3x6kLneYufbd07sn7eZ48t/v0qTpVpxvO21XV3bJNRERExEj3pnY3ICIiImIoJNRERERELSTURERERC0k1EREREQtJNRERERELSTURERERC0k1EREDDFJu0m6vN3taIWkJST9RtLTks7rq+2SrpH0ufnZxpFC0hmSjm53OxZmCTURMaJJuk/SHEnPSnq0XFiWGkR9R0j6yWDaZPuntrcZTB3NJH1S0ozSz0ck/VbSpkNQ9S7AisAKtncdjrYPp/J8v1jOy2xJN0vavN3tivZIqImIOviI7aWA9YAO4LB2NUTSqEGUlaQ3/H9Z0kHAicA3qALIqsB3gZ0GeqwGqwF/tv3yENTVLseV539p4HvABZIWaXObog0SaiKiNmw/BPwWWAdA0o6S7pT0f2Xa5J+79pX0ZUkPlXf3d0vaStK2wFeASeWd/8yy7zKSTisjJA9JOrrroilpsqRpkr4l6QngiLLt2oZjbSzppjLFc5OkjRseu0bSf0uaBjwPvL2xT5KWAY4C9rV9ge3nbL9k+ze2v1T2WUzSiZIeLv9OlLRYeWwLSQ9K+qKkx0ofdi+PHQkc3tDfPbpp+79I+lNp+ymAmtr3WUl/lPSUpMskrdbwmCXtJekv5Tn4jiQ1PP75Una2pLskrVe2ryzpl5I6Jd0r6YAWn38DPwOWpwp/SHqTpMMk3V/6f1Y5p6+dm6b+3Cdp63L7CEm/KGVml9dSR8O+75V0S3nsXGDxhsfGSrqo9PtJSVO7C6wxtHKCI6I2JK0CbA/cKmlN4BzgQGAccAnwG0mLSnonsB+wge0xwIeA+2xfSjUacq7tpWy/p1R9BvAy8A7gvcA2QOO6kvcBf6O6kP53U5uWBy4Gvg2sAJwAXCxphYbdPgXsCYwB7m/q1kZUF8sLe+n6fwHvByYA7wE2ZN7Rqn8ClgHeAuwBfEfScra/1tTf05raPha4oNQ1FvgrsEnD4ztRhcCdqc7xVKpz3mgHYANgXeBfqc41knYFjgA+TTXCsiPwRLnw/waYWdq7FXCgpA/10v+u9ixS6rsXeLRsnlz+bUkVGJcCTumrrgY7Aj8HlgWmdJWVtCjwK+BsqhB1HvCxhnJfBB6kOi8rUp2n/C7RMEuoiYg6+JWk/wOuBX5PdaGeBFxs+wrbLwHfBJYANgZeARYD1pY02vZ9tv/aXcWSVqQKSgeWUZLHgG8BH2/Y7WHbJ9t+2facpio+DPzF9tnl8XOAPwEfadjnDNt3lsdfaiq/AvB4H9NDuwFH2X7MdidwJFVQ6vJSefwl25cAzwLv7KW+LtsDd9o+v7TrROAfDY/vBfyP7T+W9n0DmNA4WgMcY/v/bP8duJoqeEEVCo+zfZMr99i+nyoAjbN9lO0Xbf8N+BHznu9mB5fn/9nSxq/afqXh3Jxg+2+2nwX+E/i4Wp8mvNb2JaW+s6lCI1QhcjRwYjmv5wM3NZR7CVgJWK08PtX5scVhl1ATEXUw0faytlezvU8JFivTMOph+1XgAeAttu+hGsE5AnhM0s8lrdxD3atRXbweKVMJ/wf8APh/Dfs80Evb5mlHcT/VKEQr5Z8AxvZxEW4+xv1l22t1NIWi56lGLPqycmPbykW5sa2rASc1nJcnqaanGvvWGIIaj7sK1chPs9WAlbvqLPV+hTKd1INv2l4WWJJqTdXxkrZr6EPzuRnVR32Nmtu/eHkuVgYeagoqjcc5HrgHuFzS3yQd2uLxYhASaiKirh6mukAC1SJcqgvpQwC2f2Z707KPgWPLrs3vph8AXgDGluC0rO2lbb+rYZ/e3oHP045i1a52tFD++nL8if04xqpl22A9QnXOgHnOYZcHgH9vOC/L2l7C9nUt1P0AsHoP2+9tqnOM7e37qrCM+NwBTKMaIYPuz83LVNNTz1EFoa7+LUI1XdSKR4C3NK4RKnV3tWW27S/afjvVFNZBkrZqse4YoISaiKirXwAfVrUAeDTVGocXgOskvVPSB8ti2rnAHODVUu5RYHzXok7bjwCXA/8raemy8HR1tf6x4UuANVV9JHuUpEnA2sBFrRS2/TTVYt7vSJooaUlJoyVtJ+m4sts5wGGSxpV1MIcDg/pYenEx8C5JO5fRiQOo1ud0+T7wn5LeBa8tqN61xbpPpZo2Wl+Vd5Rpq+nAbFULuZeQtIikdSRt0EqlktYCNgXuLJvOAb4g6W2qPurftYboZeDPVCMvHy6vkcOopiVbcT1VODqgPB87U61l6mrHDqVPAp6mmvJ8tfuqYqgk1ERELdm+G/g34GTgcao1LB+x/SLVheuYsv0fVFNJ/1mKnlf+PiHplnL708CiwF3AU8D5VOslWmnHE1SLZb9INZV0CLCD7cf70Zf/BQ6iuuh2Uo1m7Ee1UBXgaGAGMAu4HbilbBuU0sZdqc7VE8AaVKMgXY9fSDXC9XNJzwB3ANt1U1V3dZ9Htaj6Z8Ds0pfly9qVHajW3txL9RydSrXQuSeHqPr01nNUAfTHVFOEAKdTrYX5Q6lvLrB/acPTwD6l/oeoRm4epAXldbQz1SLkJ6nWcF3QsMsawO+o1vlcD3zX9tWt1B0Dp6xbioiIiDrISE1ERETUQkJNRERE1EJCTURERNRCQk1ERETUwoB/eC0iBmfs2LEeP358u5sRETGi3HzzzY/b7vb7hBJqItpk/PjxzJgxo93NiIgYUSQ1f0P3azL9FBEREbWQUBMRERG1kFATERERtZBQExEREbWQUBMRERG1kFATERERtZBQExEREbWQUBMRERG1kC/fixiJOqfBS7Pb3Yo3Gj0Gxm3S7lZExEIqoSZiJHppNize7beEt9fczna3ICIWYpl+ioiIiFpIqImIiIhaSKiJiIiIWkioiYiIiFpIqImIiIhaSKiJiIiIWkioiYiIiFpIqImIiIhaSKiJiIiIWkioiYiIiFpIqImIiIhaSKiJiIiIWkioiYiIiFpIqImIiIhaSKiJiIiIWkioiYiIiFpIqImIiIhaSKiJiIiIWkioiYiIiFroM9RIekXSbZLukHSepCX7cwBJ4yV9ciCNk3TdQMq1UO+ukv4o6epB1jNO0o2SbpX0gVbqlbSypPMHc9yGutYqz82tklYfijob6r5P0tihrHMAbVhW0j4N94fy3N0n6XZJHeX+fpLukeRW+y3pM5L+Uv59pmH71ZKe7ao7IiLmj1Et7DPH9gQAST8F9gJO6McxxgOfBH7WagFJo2y/bHvj/pZpcfc9gM/bvrbV+nuwFXC77c+VNlzaV722HwZ2GeRxu0wEzrd9dCs7SxIg268O0fFb1s/np8uywD7Ad2HIzx3AlrYfL7enARcB17RSUNLywNeADsDAzZKm2H7K9paSWqpnQG4+EP5xFbxp9LAdYsCWXAVW3rbdrYiIhVR/p5+mAu+QtLykX0maJekGSesCSNq8jBx0jR6MAY4BPlC2fUHSIpKOl3RTKf/vpewWkqZKmgLcVbY9W/6qlLmjvLue1FOZRpI+Ufa/Q9KxZdvhwKbAaZKO76bMl0uZmZKOKds+X9o7U9IvJS0paQJwHLBT6dvXGuvtpZ/jJd1Rbk+WdIGkS8u7/eMa2rGNpOsl3VJGyJZqauf2wIHA3l0jQ5IOKn29Q9KBDce7W9JZwB3AKk31bFWeq9slnS5psYaHDynbp0t6R9l/11L/TEl/KNtaek4lHSNp34ZjHyHpYElLSbqy9PV2STuVXY4BVi/n9/imc7e4pB+X/W+VtGVf57Q3tm+1fV8r+xYfAq6w/aTtp4ArgD6v5pL2lDRD0ozOzs5+HC4iIvrSykgNUL3TBrYDLgWOBG61PVHSB4GzgAnAwcC+tqeVi/Bc4FDgYNs7lHr2BJ62vUG5gE6TdHk5zHrAOrbvbTr8zqX+9wBjgZu6Lqg9lZG0MnAssD7wFHC5pIm2jyptPtj2jKYy2wE7Ae+z/byqd+MAF9j+UdnnaGAP2yeXgNRhe7/y2JZd9fbSTzf1bQLwXuAF4G5JJwNzgMOArW0/J+nLwEHAUV2FbF8i6fvAs7a/KWl9YHfgfYCAGyX9vvR9DeAztm9o6u/iwBnAVrb/XILP3sCJZZenbb9b0qfLth2Aw4EP2X5I0rJlvz166Os8z4+k95Z6vlMe+1eqcDAX+KjtZ1RN/dxQgtChpeyE0t7xDc3ftzoNfrektaie3zV7Oqe2H2BovQVorPPBsq1Xtn8I/BCgo6Oj+bXQmvVPhIcvhcXHDaj4sJqboBYR7dPKSM0Skm4DZgB/B06jGpE4G8D2VcAKkpamGsI/QdIBwLI9TDdsA3y61HkjsALVRRdgejeBhnK8c2y/YvtR4PfABn2U2QC4xnZnacdPgc366OvWwI9tP1/69mTZvk4Zcbgd2A14Vx/19NXPRlfaftr2XKrRptWA9wNrU4WD24DPlO292RS40PZztp8FLgA+UB67vznQFO8E7rX953L/TOY9R+c0/N2o3J4GnCHp88AiLfT1tefH9q3A/1O1NuY9wFMlbAj4hqRZwO+owsGKLfT3J6XePwH3A12hprtzGhERNdevNTVdJHW7o+1jJF0MbE91Qf5QN7sJ2N/2ZU11bgE810J7mg2kTH+dAUy0PVPSZGCLFsr01M/xTfu90HD7FarnRFRTG58YYHubDfQcufm27b0kvQ/4MNU6kvXp33N6HtW6mH8Czi3bdgPGAevbfknSfcDiA2wzdH9Oh9pDzPs6eCstrseJiIjhMdCPdE+luhB1XbgeL1MHq9u+3faxwE3AWsBsYExD2cuo1oGMLuXXlPTmFo43qazdGEc1mjC9jzLTgc0ljZW0CPAJqhGe3lwB7K7yCa+G6acxwCOlzbv1UUeXgfSzyw3AJg3rWN7cMLXSk6nARFXrfd4MfLRs683dwPiu4wCfYt5zNKnh7/WlLavbvtH24UAn1Rqd/vT1XODjVMHmvLJtGeCxEmi25PWRlebXTnN/u16DawKrlv4MKUkblmm5ZpcB20haTtJyVKNVl3WzX0REzCcDfQd7BHB6mS54nmp6BODAclF6FbgT+G25/YqkmVQjHidRfSLqFlVDPp1Un+LpzYVU0x8zqUYMDrH9j7KWolu2H5F0KHA11UjCxbZ/3dtBbF+qagHwDEkvApcAXwG+SjWt0ln+9nShbXQq/e9nVzs6y4jQOXp94e5hwJ97KXOLpDN4PeydavvWbkaGGsvMlbQ7cF5ZM3UT8P2GXZYrz/ELVKEQ4HhJa1Cd0yupnpNZrfbV9p2qFpA/ZPuRsvmnwG/K9N4M4E9l3yckTVO1OPi3vL4WB6pPRH2vlHkZmGz7hZ5GEftSpkwPoRpBmiXpkvKptlWp1jg19+NJSV+nOmcARzVMV0ZERBvIHthaxYiRrExxdTR8pLun/Y4HzrY9q5/1X0M3i9EbdXR0eMaMHh/u3YK8UDgf6Y6IYSTpZtvdfg9YvlE4FladwJXq4wvybH9pAIHmauDtwEuDaF9ERPTTcCygjFjg2d6g770GXPeWw1V3RET0LCM1ERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVELo9rdgIgYgNFjYG5nu1vxRqPHtLsFEbEQS6iJGInGbdLuFkRELHAy/RQRERG1kFATERERtZBQExEREbWQUBMRERG1kFATERERtZBQExEREbWQUBMRERG1kFATERERtZBQExEREbWQUBMRERG1kFATERERtZBQExEREbWQUBMRERG1kFATERERtZBQExEREbWQUBMRERG1kFATERERtZBQExEREbWQUBMRERG1kFATERERtZBQExEREbWQUBMRERG1kFATERERtZBQExEREbWQUBMRERG1kFATERERtZBQExEREbWQUBMRERG1MKrdDYiIiGjVtGkwe3a7W/FGY8bAJpu0uxWRUBMRESPG7Nkwbly7W/FGnZ3tbkFApp8iIiKiJhJqIiIiohYSaiIiIqIWEmoiIiKiFhJqIiIiohYSaiIiIqIWEmoiIiKiFhJqIiIiohYSaiIiIqIWEmoiIiKiFhJqIiIiohYSaiIiIqIWEmoiIiKiFhJqIiIiohYSaiIiIqIWEmoiIiKiFhJqIiIiohYSaiIiIqIWWgo1kl6RdJukOySdJ2nJ/hxE0nhJnxxIAyVdN5ByLdS7q6Q/Srq6H2XukzR2CNswWdIpgyjf7z60WO94SXcMZZ0DbMcESds33N9R0qFDUO94SXMk3daw7XRJj7Xab1W+LekeSbMkrVe2r17+W3l2sO2MiIj+aXWkZo7tCbbXAV4E9urnccYD/Qo1kkYB2N64v2VatAfwedtb9qddC5h+9aGf52dIDfDYE4DXQo3tKbaPGaIm/dX2hIb7ZwDb9qP8dsAa5d+ewPdKG5vrjYiI+WQgF5qpwLqSlgdOB94OPA/saXuWpM2Bk8q+BjYDjgH+ubwzPhP4dtm2BbAY8B3bP5C0BfB14ClgLWBNSc/aXkqSgOOoLiYGjrZ9bndlGhsr6RPAVwABF9v+sqTDgU2B0yRNsf2lhv23AI4CZgPvAK4G9rH9alO9vwJWARYHTrL9w7J9W+AbwCLA47a3kvRm4GRgHWA0cITtX5eqVpF0DfAW4Ce2jyz1HAR8tuxzqu0Tm44/Tx+Ar1JdWDuAl4GDbF8taTKwM7BUadPmTfX0dJxRkn4KrAfcCXza9vOSjgF2LMe43PbBksYB3wdWLWUPtD1N0hHA6lSvkb9Lehuwh+07y7GvAQ6mCtcnlXM5B9gduLc8D0tI2hT4H2AJoMP2fpLGU73+xgKdwO62/y7pDOCZch7+CTjE9vn0wfYfSp2t2gk4y7aBGyQtK2kl24/0o46I6IcDD4SrroLRo9vdkjdaZRXYtj9vi2JY9CvUlHfb2wGXAkcCt9qeKOmDwFlU76wPBvYtF7WlgLnAocDBtnco9ewJPG17A0mLAdMkXV4Osx6wju17mw6/c6n/PVQXspsk/aG3MpJWBo4F1qcKPZdLmmj7qNLmg23P6KarGwJrA/eXvu4MNF8YP2v7SUlLlLb8kuri/CNgM9v3luAH8F/AVbY/K2lZYLqk3zUcax2qYHiTpIupQtvuwPuowtiNkn5v+9augzf3QdIXq81+t6S1Sl+7At56wLq2n2w6P+t3d5xyrt5JFUCmSTod2EfSj4GPAmvZdukLVIHkW7avlbQqcBnwz+WxtYFNbc+R9AXgX4GvSVoJWKm0fWngA7ZflrQ18A3bHyvBrcP2fqW9kxuafzJwpu0zJX2WKihPLI+tRBX41gKmdPPcDYW3AA803H+wbOs11JTX/p4Aq666am+7RkREP7UaapZoWH8wFTgNuBH4GIDtqyStUC5O04ATyrv8C2w/WA2yzGMbqtGeXcr9ZaiG8V8EpncTaKC6SJ1j+xXg0XLx3YDqXXlPZTYArrHdCVDatBnwqz76O93230qZc8qxmy+MB0j6aLm9Smn/OOAPXW1pCBHbADtKOrjcX5zXRzWusP1EOdYF5VgGLrT9XMP2DwCvhZpubEp1ocf2nyTdz+ujVlc0B5qGMt0dZwrwgO1pZb+fAAcAJ1KF1NMkXQRcVB7fGli74XleugRagCm255TbvwAuB75GFW66zukywJmS1ih9b+V92EZUYRPgbKpRvC6/KiNrd0lasYW65psyovdDgI6ODre5OREjyoknwqWXwrhx7W7JG3V2trsFAa2HmjnN6wS6CSoA2D6mjDZsTzUC86FudhOwv+3LmurcAniuxTY1GkiZ3jRfbOa5X9q5NbBRmZK5hiqo9ETAx2zf3VTP+/o61hAZyPl5Q7vKSMqGwFbALsB+wAepRqjeb3tuY4HyGnmuoYKHJD0haV1gEq+vzfo6cLXtj5YpoGsG0N5GLzQ2Y5B19eQhqjDb5a1lW0REtMlgPtI9FdgNXrvIP277GUmr277d9rHATVRTALOBMQ1lLwP2ljS6lF+zrDvp63iTJC1S1nBsBkzvo8x0YHNJYyUtAnwC+H0LfdtQ0tskvYnq4ntt0+PLAE+VQLMW8P6y/QZgs7J2hIbpp8uA/cu6ICS9t6Guf5G0fJnGmkg10jUVmChpyXJePlq29abx+ViTaiTo7l5L9H6cVSVtVG5/Eri2jL4sY/sS4AtUU4FQjb7s31WppAm9HPNc4JBSz6yybRleDwSTG/Ztft00ug74eLm9G32fnwGRtJ+k/bp5aArwaVXeTzWdmvU0ERFtNJhQcwSwvqRZVIt+P1O2H6jqo9+zgJeA3wKzgFckzSzrKk4F7gJuUfUR2h/Q96jRhaWemcBVVAtA/9FbgXKROZRqse9M4OaGBbq9uQk4Bfgj1YLVC5sev5RqIe0fqfp+QzleJ9V6iQskzaS6gEM1EjEamCXpznK/y3Tgl6Vvv7Q9w/YtVJ/GmU41zXdq43qaHnwXeJOk28txJ9t+obcCfRznbmDf0sflqBYhjwEuKs/ttcBBZd8DgA5VH22+i94/HXc+VRj5RcO244D/kXQr874Orqaa1rpN0qSmevYHdi9t+RTwH731tS9lmvF64J2SHpS0R3loLeCJbopcAvwNuIdqHdU+gzl+REQMnqoPb0SXMur02qLmqJ8yxXVR+YqCvva9CNjZ9ov9PMaztpfqbZ+Ojg7PmNHdOvWI6MmCvKYmn36aPyTdbLuju8fyjcKxMHoFWKZh8XuPbO/Qn0Cj8uV7wKMDb15ERAxE276MbUFl+xoGv1A1FmC2H2DeRb5DWfdfqb56ICIi5rOM1EREREQtJNRERERELSTURERERC0k1EREREQtJNRERERELSTURERERC0k1EREREQtJNRERERELSTURERERC0k1EREREQtJNRERERELSTURERERC0k1EREREQtJNRERERELSTURERERC2MancDIiIiWjVmDHR2trsVbzRmTLtbEJBQExERI8gmm7S7BbEgy/RTRERE1EJCTURERNRCQk1ERETUQkJNRERE1EJCTURERNRCQk1ERETUQkJNRERE1EJCTURERNRCQk1ERETUQkJNRERE1EJCTURERNRCQk1ERETUQkJNRERE1EJCTURERNRCQk1ERETUQkJNRERE1EJCTURERNRCQk1ERETUQkJNRERE1EJCTURERNRCQk1ERETUQkJNRERE1EJCTURERNRCQk1ERETUQkJNRERE1EJCTURERNRCQk1ERETUQkJNRERE1MKodjcgImLEmTYNZs9udysiRq4xY2CTTYa82oSaiIj+mj0bxo1rdysiRq7OzmGpNtNPERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVELCTURERFRC4MKNZJekXSbpDsknSdpyX6WHy/pkwM89nUDKddCvbtK+qOkq4ep/r0kfbq/j/VS3/GS7pR0/NC08LV6J0s6ZSjrHGA7Jkpau+H+UZK2HoJ6J0vqlHRqub+CpKslPdtqvyUtL+kKSX8pf5cr2ydJukfSRYNtZ0REtG6wIzVzbE+wvQ7wIrBXP8uPB/oVaiSNArC9cX/LtGgP4PO2t+xPu1pl+/u2z2reLmlUT4/1YU9gXdtfamXnfp6LITXAY08EXgs1tg+3/bshatK5tj9Xbs8Fvgoc3I/yhwJX2l4DuLLcx/a5wOd6KxgREUNvKC9wU4F1JS0PnA68HXge2NP2LEmbAyeVfQ1sBhwD/LOk24AzgW+XbVsAiwHfsf0DSVsAXweeAtYC1pT0rO2lJAk4Dtiu1Hu07XO7K9PYWEmfAL4CCLjY9pclHQ5sCpwmaUpjUJC0FPBrYDlgNHCY7V9LejPwC+CtwCLA18vx7yvbtwPmAJ+0fY+kI4BnbX9T0jXAbeWY50ga0/TYjcCWwLLAHranNvVhCrAUcLOk/yn7nw6MBTqB3W3/XdIZVBft9wLTgIMa6lgc+B7QAbwMHGS7a5RqldKOtwA/sX1kL/1dHzihtOdxYLLtR5r6+BtJnwXeZvvVUtefqF4rk6kC2qLAPcCngAnAjsDmkg4DPkYVPC6yfb6krYBvUr2ObwL2tv1COfdnAh8pz9Wutv9EL2w/B1wr6R297ddkJ6rXKuV41wBf7kf5GIkOPBCuugpGj253SyJGrlVWgW23HfJqhyTUlHfg2wGXAkcCt9qeKOmDwFlUF6eDgX1tTysBYS7VO9uDbe9Q6tkTeNr2BpIWA6ZJurwcZj1gHdv3Nh1+51L/e6gu5jdJ+kNvZSStDBwLrE8Vei6XNNH2UaXNB9ue0XScucBHbT8jaSxwQwkV2wIP2/5wqXuZhjJP2353mVI6Edihm9O3qO2OUvaIpsdG2d5Q0vbA14B5pl1s71jC3YRS/jfAmbbPLOHh21QjHVCFkI1tv9J0jH2rqvxuSWuVc9EVADcE1qEKpzdJuhhYrbm/kkYDJwM72e6UNAn4b+Cz3fRxPWBz4OpyPi6z/ZKkC2z/qOxzNFWIO7mc44tsn18eo/xdHDgD2Mr2nyWdBexdzjPA47bXk7QP1WtvOEZOVrT9SLn9D2DFvgqU1/ieAKuuuuowNCkiYuE12FCzRBllgWqk5jSq0YKPAdi+qqxVWJpqhOAEST8FLrD9YNcFqsE2VKM9u5T7ywBrUE1tTe8m0EAZ5SgX60cl/R7YAHimlzIbANfY7gQobdoM+FUvfRXwDUmbAa9SjV6sCNwO/K+kY6kuvo2jKec0/P1WD/We28sxLyh/b6aaquvLRlQhD+BsqhGsLud1E2igOn8nA9j+k6T7eX1U6wrbTwBIuqDsewlN/ZW0DlX4uaI8p4sAjzQc49ym25OoQs3Hge+W7euUMLMs1WjPZX309Z3Avbb/XO6fSRXQTiz3G8/dzgwz25bkFvb7IfBDgI6Ojj73jwXQiSfCpZfCuHHtbknEyNXZOSzVDjbUzOkaJejSTVABwPYx5Z3+9lQjMB/qZjcB+9ue54JWppKeG0D7BlKmJ7sB44D1y8jCfcDiZZRgPap+HS3pSttHlTKNF62eLmC9tfGF8vcVBv9cDeRcNLfZ3fUXuBC40/ZGLRx7ClU4XJ5qpOyqsv0MYKLtmZIm8/q0zkAN5bnryaOSVirTbCsBjw3TcSIiogXD8ZHuqVQBoCuMPF6mbFa3fbvtY6nWP6wFzAbGNJS9DNi7TGcgac2y7qKv402StIikcVQjLtP7KDOdap3GWEmLAJ8Aft9HmWWAx0qg2ZJqGqZrKut52z8Bjqea8uoyqeHv9X3UPxSuoxr9gOo5mNrLvl0an681gVWBu8tj/1I+4bME1TTWtB76ezcwTtJGpZ7Rkt7V3cFsP0v1/J9ENdLTNXo0BnikPPe7NRRpfo10uRsY37AG5lP0/RwOiKSzJG3YzUNTgM+U25+hWnMVERFtMhzvYI8ATpc0i2otRtf/9A8sYeBV4E7gt+X2K5JmUr1TP4lqmuWWsgC4k9fXhPTkQqppl5lUIwuH2P5HWR/SrfLO+lCqKZCuhcJ9XZB+SrXQ9XZgBtUCV4B3A8dLehV4iWpdR5flynl4gSo4Dbf9gR9L+hJloXALZb4LfK/062WqBb4vlBG36cAvqdbj/MT2jDLCNk9/bb9Ypgy/XdYUjaKaBrqzh2OeC5zHvKMxX6Wauuwsf7uCzM+BH0k6AOialsT2XEm7A+eVNV03Ad9vob89KqNvSwOLSpoIbGP7LmBd4OFuihwD/ELSHsD9wL8O5vgRETE4sjOtPxzKBbLD9uPtbku8UZni6rC9Xx/7LQ2cZnvXfta/BQ2L4LvT0dHhGTOa16PHiJA1NRGD09k54E8/Sbq568MnzfKNwrGwmgNsp/Llez2x/cwAAs0kqhGwpwbRvoiI6Ke2fRFb3dke3+42RM/KF+T19smzBbLuiIjoWUZqIiIiohYSaiIiIqIWEmoiIiKiFhJqIiIiohYSaiIiIqIWEmoiIiKiFhJqIiIiohYSaiIiIqIWEmoiIiKiFhJqIiIiohYSaiIiIqIWEmoiIiKiFhJqIiIiohYSaiIiIqIWEmoiIiKiFka1uwERESPOmDHQ2dnuVkSMXGPGDEu1CTUREf21ySbtbkFEdCPTTxEREVELCTURERFRCwk1ERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVELCTURERFRC7Ld7jZELJQkdQL3D7D4WODxIWzOgmhh6CMsHP1MH+thQenjarbHdfdAQk3ECCRphu2OdrdjOC0MfYSFo5/pYz2MhD5m+ikiIiJqIaEmIiIiaiGhJmJk+mG7GzAfLAx9hIWjn+ljPSzwfcyamoiIiKiFjNRERERELSTURERERC0k1EQswCRtK+luSfdIOrSbxxeTdG55/EZJ49vQzEFpoY+bSbpF0suSdmlHGwerhT4eJOkuSbMkXSlptXa0czBa6ONekm6XdJukayWt3Y52DkZffWzY72OSLGmB/vhzd1p4HidL6izP422SPteOdvbIdv7lX/4tgP+ARYC/Am8HFgVmAms37bMP8P1y++PAue1u9zD0cTywLnAWsEu72zxMfdwSWLLc3rumz+PSDbd3BC5td7uHuo9lvzHAH4AbgI52t3sYnsfJwCntbmtP/zJSE7Hg2hC4x/bfbL8I/BzYqWmfnYAzy+3zga0kaT62cbD67KPt+2zPAl5tRwOHQCt9vNr28+XuDcBb53MbB6uVPj7TcPfNwEj7lEor/z0CfB04Fpg7Pxs3RFrt4wIroSZiwfUW4IGG+w+Wbd3uY/tl4GlghfnSuqHRSh9Huv72cQ/gt8PaoqHXUh8l7Svpr8BxwAHzqW1Dpc8+SloPWMX2xfOzYUOo1dfqx8pU6fmSVpk/TWtNQk1ExAJC0r8BHcDx7W7LcLD9HdurA18GDmt3e4aSpDcBJwBfbHdbhtlvgPG21wWu4PWR4gVCQk3EgushoPFd0FvLtm73kTQKWAZ4Yr60bmi00seRrqU+Stoa+C9gR9svzKe2DZX+Po8/ByYOZ4OGQV99HAOsA1wj6T7g/cCUEbZYuM/n0fYTDa/PU4H151PbWpJQE7HguglYQ9LbJC1KtRB4StM+U4DPlNu7AFe5rOYbIVrp40jXZx8lvRf4AVWgeawNbRysVvq4RsPdDwN/mY/tGwq99tH207bH2h5vezzV2qgdbc9oT3MHpJXncaWGuzsCf5yP7evTqHY3ICK6Z/tlSfsBl1F9KuF023dKOgqYYXsKcBpwtqR7gCep/ic0YrTSR0kbABcCywEfkXSk7Xe1sdn90uLzeDywFHBeWef9d9s7tq3R/dRiH/cro1EvAU/xehgfEVrs44jWYh8PkLQj8DLV/3Mmt63B3cjPJEREREQtZPopIiIiaiGhJiIiImohoSYiIiJqIaEmIiIiaiGhJiIiImohoSYiYghJeqX8evEdks6TtGQ/y4+X9MkBHvu6gZQbKpLukzS2H/sfIengbravLOn8cnsLSReV2zt2/XK0pIkj8Ze+Y3gl1EREDK05tifYXgd4Edirn+XHA/0KNeXbpLG9cX/L9NdAy/WH7Ydt79LN9im2jyl3JwIJNTGPhJqIiOEzFXiHpOUl/ar8COANktYFkLR5GdW5TdKtksYAxwAfKNu+IGkRScdLuqmU//dSdgtJUyVNAe4q254tf1XK3CHpdkmTeirTSNKzkr4l6U5JV0oaV7ZfI+lESTOA/5C0VWnv7ZJOl7RYQzWHlO3TJb2jlP+IpBtLmd9JWrFh//dIul7SXyR9vuw/XtId3bRvsqRTJG1M9W22x5fztLqkWxr2W6Pxfiw8EmoiIoZBGdHYDrgdOBK4tfwI4FeAs8puBwP72p4AfACYAxwKTC2jPd+i+tXup21vAGwAfF7S20r59YD/sL1m0+F3BiYA7wG2prr4r9RHGYA3U31z7LuA3wNfa3hsUdsdwHeAM4BJtt9N9c30ezfs93TZfgpwYtl2LfB+2++l+t2nQxr2Xxf4ILARcLiklbtp1zxsX0f19f1fKufpr8DTkiaUXXYHftxXPVE/CTUREUNrCUm3ATOAv1P9lMWmwNkAtq8CVpC0NDANOEHSAcCytl/upr5tgE+XOm8EVgC6fkdpuu17uymzKXCO7VdsP0oVUDboowzAq8C55fZPSj1dura/E7jX9p/L/TOBzRr2O6fh70bl9luByyTdDnwJaPyZi1/bnmP7ceBqYMMe2taXU4HdJS0CTAJ+NsB6YgRLqImIGFpda2om2N7f9os97VjWh3wOWAKYJmmtbnYTsH9DnW+zfXl57LkBtK8/ZRp/R6fVcu7m9snAKWUE59+BxXvYv7v7rfol1cjYDsDNtkfSr9XHEEmoiYgYflOB3aBa1wI8bvsZSavbvt32sVS/kLwWMBsY01D2MmBvSaNL+TUlvbmF400q63HGUY2kTG+hnW+i+rV3qBYrX9vNPncD47vWywCfohoJ6jKp4e/15fYywEPldvMPWe4kaXFJKwBbUJ2HVsxznmzPpTpX3yNTTwut/Ep3RMTwOwI4XdIs4Hlev7AfKGlLqmmfO4HfltuvSJpJtXblJKpPRN2i6ie8O6k++dObC6mmfmZSjXwcYvsfPYwENXoO2FDSYcBjvB5QXmN7rqTdqX5RfBRVCPl+wy7LlX6+AHyiof/nSXoKuAp4W8P+s6imncYCX7f9sKTxfbQTqrU5PypTd7uUdTU/BT4KXN5ryait/Ep3REQA1aefbC/V7nYMVPnOm2Vsf7XdbYn2yEhNRESMeJIuBFan+iRVLKQyUhMRERG1kIXCERERUQsJNREREVELCTURERFRCwk1ERERUQsJNREREVEL/x9VMO+uAhoUbQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.3\n",
    "\n",
    "# Plot the first horizontal line (stick) with confidence interval\n",
    "\n",
    "count = 1 # determines y-position on graph\n",
    "\n",
    "for posterior in posteriors:\n",
    "    ax.plot([posterior.lower, posterior.upper], \n",
    "            [count, count], label=posterior.name, color=posterior.color)\n",
    "    ax.fill_betweenx([count - bar_width, count + bar_width], posterior.lower, posterior.upper,\n",
    "                      color=posterior.color, alpha=0.2)\n",
    "\n",
    "    count += 1 # increment height\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Posterior probability')\n",
    "ax.set_yticks([1, 2, 3])\n",
    "ax.set_yticklabels([posterior.name for posterior in posteriors])\n",
    "ax.set_title(f\"Posterior Confidence Bounds\")\n",
    "\n",
    "# Add a legend\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding IsMax\n",
    "Note that in this experiment we use normalized posteriors for intuition $M_i = \\frac{\\Pr(C_i|\\mathbf{x})\\Pr(C_i)}{\\Pr(x)}$ for intution, and so they sum up to 1.\n",
    "\n",
    "Theorem 4.2 makes no assumptions about the placement of the upper and lower posterior bounds. If the upper posteriors bounds do not exceed $1$, the posteriors of selected causes are independent, leaving any remaining probability to the (dependent) last cause, $C_{other}$. (One could use a similar method if the sum of upper posteriors exceeded 1, but formulating the probability density function would require additional steps. We went with the easier approach since this example is for intuition.)\n",
    "\n",
    "Here's the reasoning:\n",
    "\n",
    "<u> Independence of Posteriors </u>:\n",
    "\n",
    "\n",
    "Suppose we have $k$ posteriors (this includes $M_{other}$, the combined posterior that anything not in our selected 'causes' was the cause). Treat each $M_i \\in \\mathcal{M}$ as a random variable.\n",
    "Then, **if the sum of upper bounds of every posterior in $\\mathcal{M}$ does not exceed 1 (or $\\Pr(\\mathbf{x})$)**, we can let the first $k-1$ causes be independent (because of this upper bound, selecting *any* random posteriors within this range and adding them up will *never* exceed $\\Pr(\\mathbf{x})$) while the last posterior, $M_{other}$, is a fully dependent random variable $M_{other} = 1-\\sum_i{M_i}$ (or  $M_{other} = \\Pr(\\mathbf{x})-\\sum_i{M_i}$). \n",
    "\n",
    "<u> Pr(IsMax(M_i)) is just expected value of an indicator function </u>:\n",
    "\n",
    "For simplicity let $X$, $Y$, $Z$, ... be the chosen (independent) posterior random variables, and let $x$, $y$, and $z$ be the specific values they take on. Also, suppose we are finding the probability that $X$ is the maximum posterior. Then, let this be the indicator function that x is the maximum.\n",
    "$$\n",
    "\\mathbf{1}_{\\{{x}_{max}\\}}(x,y,z) = \\begin{cases} \n",
    "1 & \\text{if } x = \\max(\\{x,y,z,1-(x+y+z)\\}) \\\\ \n",
    "0 & \\text{otherwise }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The expected value of this indicator function basically is the same value as (1) tallying up the total number of configurations of $x$, $y$, $z$, (and $(1-x-y-z)$) where $x$ is the maximum, and then (2) dividing it by the total number of configurations of $x$, $y$, and $z$. This is the same thing as the probability that $X=x$ is the maximum.\n",
    "\n",
    "We can find this with LOTUS:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Pr(IsMax(X)) &= \\int_{x_l}^{x_u} \\int_{y_l}^{y_u} \\int_{z_l}^{z_u} \\mathbf{1}_{\\{{x}_{max}\\}}(x,y,z)f(x, y, z) \\, dz \\, dy \\, dx\\\\\n",
    "&= \\int_{x_l}^{x_u} \\int_{y_l}^{y_u} \\int_{z_l}^{z_u} \\mathbf{1}_{\\{{x}_{max}\\}}(x,y,z)f(x)f(y)f(z) \\, dz \\, dy \\, dx\\\\\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator(x,y,z):\n",
    "    return int(x == max(x,y,z,1-(x+y+z))) # ew\n",
    "\n",
    "def integrand(x:float, x_obj:Posterior, y:float, y_obj:Posterior, \n",
    "              z:float, z_obj:Posterior):\n",
    "    \"\"\"integrand for expected value\"\"\"\n",
    "    return indicator(x,y,z)*x_obj.get_pdf(x)*y_obj.get_pdf(y)*z_obj.get_pdf(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the integral (Monte-carlo integration technique, scipy complained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as spi\n",
    "from typing import List\n",
    "\n",
    "def monte_carlo_integration(function, x_obj, y_obj, z_obj, num_samples=10000000):\n",
    "    \"\"\"\n",
    "    Estimate the integral of a function over a 3D domain using Monte Carlo integration. \n",
    "\n",
    "    Parameters:\n",
    "    - function: callable, the function to integrate. It should accept three arguments (x, y, z).\n",
    "    - bounds1: tuple, the lower and upper bounds for the first variable (x).\n",
    "    - bounds2: tuple, the lower and upper bounds for the second variable (y).\n",
    "    - bounds3: tuple, the lower and upper bounds for the third variable (z).\n",
    "    - num_samples: int, the number of random samples to use for the estimation (default: 1,000,000).\n",
    "\n",
    "    Returns:\n",
    "    - integral_estimate: float, the estimated value of the integral.\n",
    "    - standard_error: float, the estimated standard error of the integral.\n",
    "    \"\"\"\n",
    "    x_l, x_u = x_obj.lower, x_obj.upper\n",
    "    y_l, y_u = y_obj.lower, y_obj.upper\n",
    "    z_l, z_u = z_obj.lower, z_obj.upper\n",
    "\n",
    "    # Generate random samples\n",
    "    x_samples = np.random.uniform(x_l, x_u, num_samples)\n",
    "    y_samples = np.random.uniform(y_l, y_u, num_samples)\n",
    "    z_samples = np.random.uniform(z_l, z_u, num_samples)\n",
    "\n",
    "    # Evaluate the integrand at the sample points\n",
    "    sample_evaluations = np.array([function(x, y, z) for x, y, z in zip(x_samples, y_samples, z_samples)])\n",
    "\n",
    "    # Compute the volume of the integration region\n",
    "    volume = (x_u - x_l) * (y_u - y_l) * (z_u - z_l)\n",
    "\n",
    "    # Estimate the integral as the mean of the evaluations times the volume\n",
    "    integral_estimate = volume * np.mean(sample_evaluations)\n",
    "\n",
    "    # Compute the standard error of the mean\n",
    "    standard_error = volume * np.std(sample_evaluations) / np.sqrt(num_samples)\n",
    "\n",
    "    return integral_estimate, standard_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_isMax_estimate(chosen:Posterior, rest:List[Posterior]):\n",
    "    return monte_carlo_integration(lambda x,y,z: integrand(x, chosen, y, rest[0], z, rest[1]), \n",
    "                                                                  chosen, rest[0], rest[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsMax of Aspirin\n",
      "Estimated integral: 0.45448460000000024\n",
      "Estimated standard error: 0.00015745546824745085\n"
     ]
    }
   ],
   "source": [
    "ismax_aspirin, standard_error_aspirin = get_isMax_estimate(aspirin_post, [placebo_post, caffeine_post])\n",
    "\n",
    "print(\"IsMax of Aspirin\")\n",
    "print(f\"Estimated integral: {integral_estimate_aspirin}\")\n",
    "print(f\"Estimated standard error: {standard_error_aspirin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsMax of Placebo\n",
      "Placebo integral: 0.3616113999999998\n",
      "Estimated standard error: 0.00015194614783713338\n"
     ]
    }
   ],
   "source": [
    "# same with placebo (this is zero since C_other would have the maximum posterior)\n",
    "ismax_placebo, standard_error_placebo = get_isMax_estimate(placebo_post, [caffeine_post, aspirin_post])\n",
    "print(\"IsMax of Placebo\")\n",
    "print(f\"Placebo integral: {integral_estimate_placebo}\")\n",
    "print(f\"Estimated standard error: {standard_error_placebo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsMax of Caffeine\n",
      "Caffeine integral: 0.0\n",
      "Estimated standard error: 0.0\n"
     ]
    }
   ],
   "source": [
    "ismax_caffeine, standard_error_caffiene = get_isMax_estimate(caffeine_post, [placebo_post, aspirin_post])\n",
    "print(\"IsMax of Caffeine\")\n",
    "print(f\"Caffeine integral: {integral_estimate_caffiene}\")\n",
    "print(f\"Estimated standard error: {standard_error_caffiene}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsMax of C_other: 0.18387079999999956\n"
     ]
    }
   ],
   "source": [
    "ismax_other = 1 - np.sum([ismax_placebo, ismax_caffeine, ismax_aspirin])\n",
    "print(f\"IsMax of C_other: {ismax_other}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating BER\n",
    "\n",
    "This example is small enough to directly calculate lower and upper bounds of BER with the summation form of Definition 4.3 (Sekeh et. al.) without the use of estimation techniques. (For more complex problems with many causes $|\\mathcal{O}| = 2^{|\\mathcal{C}|}$ may be very large, so it may be more practical apply the estimation techniques while treating the observations as continuous).\n",
    "\n",
    "$$\\epsilon = 1 - \\sum_{\\mathbf{x} \\in \\mathcal{O}} \\Pr(\\textbf{x})\\max_i \\Pr(C_i|\\textbf{x}).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helpers\n",
    "def get_max(posteriors:List[float]):\n",
    "    # return maximum posterior (including M_other)\n",
    "    posteriors.append(1 - sum(posteriors)) # append remaining probability, should be very close to 0\n",
    "    return max(posteriors)\n",
    "\n",
    "\n",
    "def get_posteriors(i:int, j:int, cause_objs:List[Cause], upper:bool):\n",
    "    # get list of poteriors for the [i,j] observation vector\n",
    "    posteriors = []\n",
    "    for cause in cause_objs:\n",
    "        posterior_obj = cause.posteriors[i][j]\n",
    "        if upper:\n",
    "            posteriors.append(posterior_obj.upper)\n",
    "        else:\n",
    "            posteriors.append(posterior_obj.lower)\n",
    "    return posteriors    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upper bound of BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER upper bounds: 0.22999999999999998\n"
     ]
    }
   ],
   "source": [
    "ber_upper = 1 - sum([EVIDENCE_DIST[i][j]*get_max(get_posteriors(i,j, [aspirin, placebo, caffeine], \n",
    "                                                                upper=True)) \n",
    "                                                                for i in [0,1] for j in [0,1]])\n",
    "print(f\"BER upper bounds: {ber_upper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER lower bounds: 0.21699999999999997\n"
     ]
    }
   ],
   "source": [
    "ber_lower = 1 - sum([EVIDENCE_DIST[i][j]*get_max(get_posteriors(i,j, [aspirin, placebo, caffeine], \n",
    "                                                                upper=False)) \n",
    "                                                                for i in [0,1] for j in [0,1]])\n",
    "print(f\"BER lower bounds: {ber_lower}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Abductive Error Guarantees\n",
    "Now that we have $\\epsilon_{lower}$, $\\epsilon_{upper}$, and the IsMax values for all possible causes, we can follow section 4.3 to find the final general error rate bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $\\gamma_{i,upper}$ and $\\gamma_{i,lower}$ for each cause, the error rate (when posterior $M_i$ is chosen) given the assumption that posteriors lie in their 95% confidence intervals.\n",
    "$$\n",
    "    \\gamma_{i,upper} = \\epsilon_{\\text{upper}}\\Pr(IsMax(M_i)) + (1-l_i)(1-\\Pr(IsMax(M_i)))\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\gamma_{i,lower} = \\epsilon_{\\text{lower}}\\Pr(IsMax (M_i)) + (1-u_i)(1-\\Pr(IsMax(M_i)))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the preferred observation vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "pill = 1 # did you take a pill?\n",
    "relief = 0 # was your headache relieved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aspirin': 0.5591680479999996, 'caffeine': 1.0, 'placebo': 0.508719268}\n",
      "{'aspirin': 0.3532137391999999, 'caffeine': 0.9333333333333333, 'placebo': 0.4614644572}\n"
     ]
    }
   ],
   "source": [
    "# maps cause object to probability of wrong abduction and posterior is maximum\n",
    "gamma_upper = {\n",
    "    \"aspirin\"  : ber_upper*ismax_aspirin + \n",
    "                (1-aspirin.posteriors[pill][relief].lower)*(1-ismax_aspirin),\n",
    "    \"caffeine\" : ber_upper*ismax_caffeine + \n",
    "                (1-caffeine.posteriors[pill][relief].lower)*(1-ismax_caffeine),\n",
    "    \"placebo\"  : ber_upper*ismax_placebo + \n",
    "                (1-placebo.posteriors[pill][relief].lower)*(1-ismax_placebo),\n",
    "    } \n",
    "\n",
    "gamma_lower = {\n",
    "    \"aspirin\"  : ber_lower*ismax_aspirin + \n",
    "                (1-aspirin.posteriors[pill][relief].upper)*(1-ismax_aspirin),\n",
    "    \"caffeine\" : ber_lower*ismax_caffeine + \n",
    "                (1-caffeine.posteriors[pill][relief].upper)*(1-ismax_caffeine),\n",
    "    \"placebo\"  : ber_lower*ismax_placebo + \n",
    "                (1-placebo.posteriors[pill][relief].upper)*(1-ismax_placebo),\n",
    "    } \n",
    "\n",
    "\n",
    "print(gamma_upper)\n",
    "print(gamma_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referring to the diagram of posterior bounds, causes \"aspirin\" and \"placebo\" have error rates around 50% because they are tied winners with close midpoints, and so either cause may be the true maximum posterior. Caffeine has an extremely high error rate because if it is contained inside its 95% bounds, it has no chance of being the maximum posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the final bounds.\n",
    "\n",
    "$$\\Pr(W)\\leq 1-q^k(1-\\gamma_{\\text{i, upper}})$$\n",
    "\n",
    "$$\\Pr(W)\\geq \\gamma_{\\text{i, lower}} q^k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General upper bounds of: [1, 0]\n",
      " {'aspirin': 0.6220417051539997, 'caffeine': 1.0, 'placebo': 0.5787881824015}\n",
      "General lower bounds: [1, 0]\n",
      " {'aspirin': 0.47941670515399964, 'caffeine': 0.8573749999999999, 'placebo': 0.4361631824014999}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 3 # there are 3 selected causes\n",
    "general_upper = {key : 1-(Q_CONFIDENCE**k)*(1-gamma_bound) for key, gamma_bound in gamma_upper.items()}\n",
    "\n",
    "general_lower = {key : gamma_bound*Q_CONFIDENCE**k for key, gamma_bound in gamma_upper.items()}\n",
    "\n",
    "\n",
    "print(f\"General upper bounds of: {[pill, relief]}\\n\", general_upper)\n",
    "print(f\"General lower bounds: {[pill, relief]}\\n\", general_lower)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for all other observation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general_bounds(pill, relief):\n",
    "    gamma_upper = {\n",
    "        \"aspirin\"  : ber_upper*ismax_aspirin + \n",
    "                    (1-aspirin.posteriors[pill][relief].lower)*(1-ismax_aspirin),\n",
    "        \"caffeine\" : ber_upper*ismax_caffeine + \n",
    "                    (1-caffeine.posteriors[pill][relief].lower)*(1-ismax_caffeine),\n",
    "        \"placebo\"  : ber_upper*ismax_placebo + \n",
    "                    (1-placebo.posteriors[pill][relief].lower)*(1-ismax_placebo),\n",
    "        } \n",
    "\n",
    "    gamma_lower = {\n",
    "        \"aspirin\"  : ber_lower*ismax_aspirin + \n",
    "                    (1-aspirin.posteriors[pill][relief].upper)*(1-ismax_aspirin),\n",
    "        \"caffeine\" : ber_lower*ismax_caffeine + \n",
    "                    (1-caffeine.posteriors[pill][relief].upper)*(1-ismax_caffeine),\n",
    "        \"placebo\"  : ber_lower*ismax_placebo + \n",
    "                    (1-placebo.posteriors[pill][relief].upper)*(1-ismax_placebo),\n",
    "        } \n",
    "\n",
    "\n",
    "    k = 3 # there are 3 selected causes\n",
    "    general_upper = {key : 1-(Q_CONFIDENCE**k)*(1-gamma_bound) for key, gamma_bound in gamma_upper.items()}\n",
    "\n",
    "    general_lower = {key : gamma_bound*Q_CONFIDENCE**k for key, gamma_bound in gamma_upper.items()}\n",
    "\n",
    "\n",
    "    print(f\"General upper bounds of {[pill, relief]}\\n\", general_upper)\n",
    "    print(f\"General lower bounds {[pill, relief]}\\n\", general_lower)\n",
    "    return # general_upper, general_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General upper bounds of [0, 0]\n",
      " {'aspirin': 0.6922070116839998, 'caffeine': 0.9428416666666667, 'placebo': 0.7575573379385001}\n",
      "General lower bounds [0, 0]\n",
      " {'aspirin': 0.5495820116839996, 'caffeine': 0.8002166666666666, 'placebo': 0.6149323379385}\n"
     ]
    }
   ],
   "source": [
    "get_general_bounds(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General upper bounds of [0, 1]\n",
      " {'aspirin': 0.7000031568539997, 'caffeine': 0.9142625, 'placebo': 0.7612056880515}\n",
      "General lower bounds [0, 1]\n",
      " {'aspirin': 0.5573781568539996, 'caffeine': 0.7716374999999999, 'placebo': 0.6185806880514999}\n"
     ]
    }
   ],
   "source": [
    "get_general_bounds(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General upper bounds of [1, 1]\n",
      " {'aspirin': 0.6064494148139998, 'caffeine': 0.99142625, 'placebo': 0.7557331628820001}\n",
      "General lower bounds [1, 1]\n",
      " {'aspirin': 0.4638244148139997, 'caffeine': 0.8488012499999998, 'placebo': 0.613108162882}\n"
     ]
    }
   ],
   "source": [
    "get_general_bounds(1,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
